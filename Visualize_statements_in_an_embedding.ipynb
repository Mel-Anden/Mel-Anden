{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mel-Anden/Mel-Anden/blob/main/Visualize_statements_in_an_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Actor Statements in an Embedding\n",
        "\n",
        "*DTU - Explore the controversy about Energy Island*\n",
        "\n",
        "**Goal**:\n",
        "- Compute a vector representation of each statement using an embedding model\n",
        "- Reduce dimensionality using the algorithm UMAP\n",
        "- Visualize for exploration\n",
        "\n",
        "**Purpose**: allows understanding patterns such as sub-controversies, different arguments, time dynamics and more.\n",
        "\n",
        "**How to use**:\n",
        "- Edit settings then use \"Runtime > Run all\"\n",
        "- Wait for each cell to run\n",
        "- ⚠️ You may have to restart the runtime when installing libraries\n",
        "- ⚠️ Allow the script to access your Google Drive data when prompted to\n",
        "- **RAG**: you can do retrieval-augmented generation (RAG) at the end of the notebook. Edit the query just under section *\"DIY RAG (Retrieval augmented generation)\"*, run that cell and all the subsequent ones, then copy-paste the generated prompt into an AI assistant like Claude, Gemini or ChatGPT."
      ],
      "metadata": {
        "id": "gjHZJ6oWTxQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings"
      ],
      "metadata": {
        "id": "sfunsb6KVLwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SETTINGS (edit if necessary)\n",
        "settings = {}\n",
        "settings['statements_spreadsheet_drive_URL'] = 'https://docs.google.com/spreadsheets/d/1c6U-tF4ZTi-csTkusGFaSclE2-gn3tvi0Xaj4Q8AKvk/edit?usp=sharing'\n",
        "settings['column_text'] = 'Restated version (the transformed actor statement)'\n",
        "#settings['column_text'] = 'Original statement (the source text you transformed and translated)'\n",
        "settings['recompute_embeddings'] = True # Set to True if you changed the documents\n",
        "settings['visualized_attribute'] = 'Year' # For the embedding plot\n",
        "#settings['visualized_attribute'] = 'Source medium type' # For the embedding plot"
      ],
      "metadata": {
        "id": "9zLNzVyOUlwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code\n",
        "\n",
        "(You don't have to understand what's going on here, but feel free to take a look)"
      ],
      "metadata": {
        "id": "JquYW1YjVCwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install stuff"
      ],
      "metadata": {
        "id": "8XwXM-E6Zjef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install pandas==2.0.3 gspread==5.10.0 google-auth==2.22.0 google-auth-oauthlib==1.0.0 google-auth-httplib2==0.1.0\n",
        "!pip install chromadb bokeh umap-learn"
      ],
      "metadata": {
        "id": "Pc4swiM8VJlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import json\n",
        "import umap\n",
        "\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "import bokeh\n",
        "import bokeh.plotting as bp\n",
        "from bokeh.io import output_notebook, show\n",
        "from bokeh.models import ColumnDataSource, HoverTool, CategoricalColorMapper\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "5lwgdgKIVSxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data from the spreadsheet"
      ],
      "metadata": {
        "id": "po50ZkgCZmE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the spreadsheet by its key or URL\n",
        "spreadsheet_key = settings['statements_spreadsheet_drive_URL'].split('/d/')[1].split('/edit')[0]\n",
        "sh = gc.open_by_key(spreadsheet_key)\n",
        "\n",
        "# Select the worksheet\n",
        "worksheet_name = 'Form Responses'\n",
        "worksheet = sh.worksheet(worksheet_name)"
      ],
      "metadata": {
        "id": "-cdmch--Vcly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values from the worksheet as a list of lists\n",
        "data = worksheet.get_all_values()\n",
        "\n",
        "# Create a Pandas DataFrame from the list of lists\n",
        "df = pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "# Parse dates and convert to years for convenience\n",
        "df['Year'] = pd.to_datetime(df['Date of publication (today if not available)'], format='%m/%d/%Y', errors='coerce')\n",
        "df['Year'] = df['Year'].dt.year\n",
        "\n",
        "# Display dataframe for monitoring purposes\n",
        "df"
      ],
      "metadata": {
        "id": "AazyPXBdZbdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print keys of df (for monitoring and debug purposes)\n",
        "print(df.keys())"
      ],
      "metadata": {
        "id": "09Ics6WgH6JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute embeddings"
      ],
      "metadata": {
        "id": "Y9JacBQvZ-zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ChromaDB and create a collection\n",
        "client = chromadb.Client()\n",
        "\n",
        "if settings['recompute_embeddings']:\n",
        "  # Delete the collection if it exists\n",
        "  try:\n",
        "      client.delete_collection(name=\"my_documents\")\n",
        "      print(\"Existing collection 'my_documents' deleted.\")\n",
        "  except:\n",
        "      pass  # Ignore if collection doesn't exist\n",
        "\n",
        "# Get or create the collection\n",
        "try:\n",
        "  collection = client.get_collection(name=\"my_documents\")\n",
        "except:\n",
        "  collection = client.create_collection(name=\"my_documents\")\n",
        "\n",
        "  # Get the text content and metadata from the DataFrame\n",
        "  texts = df[settings['column_text']].tolist()\n",
        "  metadata = df.drop(columns=['Original statement (the source text you transformed and translated)', 'Restated version (the transformed actor statement)']).to_dict(orient=\"records\")\n",
        "\n",
        "  # Create embeddings and add documents to the collection\n",
        "  # Instead of passing embedding_function to add(),\n",
        "  # we will create an embedding function and use it to embed the documents first\n",
        "  from chromadb.utils import embedding_functions\n",
        "  embedding_function = embedding_functions.DefaultEmbeddingFunction()\n",
        "  embeddings = embedding_function(texts) # Embed the documents\n",
        "\n",
        "  # Use DataFrame's row index as id\n",
        "  ids = df.index.astype(str).tolist()  # Convert index to strings for ChromaDB\n",
        "\n",
        "  # Add documents with embeddings and metadata\n",
        "  collection.add(\n",
        "      documents=texts,\n",
        "      metadatas=metadata,\n",
        "      embeddings=embeddings, # Pass the embeddings here\n",
        "      ids=ids # Pass the document IDs here\n",
        "  )\n",
        "print('Embeddings computed.')"
      ],
      "metadata": {
        "id": "DiILUGrDodyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = collection.get(include=['embeddings'])['embeddings']"
      ],
      "metadata": {
        "id": "actl0tKbnRIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce dimensionality\n",
        "We use UMAP to reduce the vector space to 2 dimensions"
      ],
      "metadata": {
        "id": "iZMb4TXPn0hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if settings['recompute_embeddings'] or 'umap_result' not in locals():\n",
        "  # Initialize UMAP with desired parameters\n",
        "  reducer = umap.UMAP(n_neighbors=15,\n",
        "                      n_components=2,\n",
        "                      min_dist=0.05,\n",
        "                      metric='cosine',\n",
        "                      random_state=42)\n",
        "\n",
        "  # Apply UMAP to the embeddings\n",
        "  umap_result = reducer.fit_transform(embeddings)\n",
        "\n",
        "print(\"UMAP reduction complete.\")"
      ],
      "metadata": {
        "id": "yOifSp0dnyjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize statements"
      ],
      "metadata": {
        "id": "wVU6ilHWpWgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set attribute to visualize\n",
        "painted_attribute = settings['visualized_attribute']\n",
        "painted_data = df[painted_attribute].astype(str)\n",
        "\n",
        "# Create a ColumnDataSource for Bokeh\n",
        "source = ColumnDataSource(data=dict(\n",
        "    x=umap_result[:, 0],\n",
        "    y=umap_result[:, 1],\n",
        "    attribute_to_paint=painted_data,\n",
        "    author=df['Actor '],\n",
        "    source=df['Source name (e.g. LinkedIn,  Jyske Vestkysten, Folketinget, etc.)'],\n",
        "    date=df['Date of publication (today if not available)'],\n",
        "    text=df[settings['column_text']]\n",
        "))\n",
        "\n",
        "# Get unique modalities and create a color mapper\n",
        "unique_modalities = painted_data.unique()\n",
        "unique_modalities.sort()\n",
        "color_mapper = CategoricalColorMapper(factors=list(unique_modalities), palette=bokeh.palettes.turbo(len(unique_modalities)))"
      ],
      "metadata": {
        "id": "qlgb2dKNoEmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the plot to the notebook\n",
        "output_notebook()\n",
        "\n",
        "# Create the figure\n",
        "p = bp.figure(width=700, height=700,\n",
        "            title=\"Actor statements\",\n",
        "            tools=\"pan,wheel_zoom,box_zoom,reset,hover\", match_aspect=True)\n",
        "\n",
        "# Add scatter plot with color mapping and hover tool\n",
        "p.scatter('x', 'y', source=source, size=10,\n",
        "        color={'field': 'attribute_to_paint', 'transform': color_mapper},\n",
        "        legend_group='attribute_to_paint')\n",
        "\n",
        "# Customize the plot (optional)\n",
        "p.legend.title = painted_attribute\n",
        "p.xaxis.axis_label = \"UMAP Dimension 1\"\n",
        "p.yaxis.axis_label = \"UMAP Dimension 2\"\n",
        "\n",
        "# HTML tooltip\n",
        "hover = p.select(dict(type=HoverTool))\n",
        "hover.tooltips = \"\"\"\n",
        "    <div style=\"width: 300px; word-wrap: break-word;\">\n",
        "        <div>@text</div>\n",
        "        <div><em>&mdash;@author, @source, @date</em></div>\n",
        "        <br>\n",
        "    </div>\n",
        "\"\"\"\n",
        "hover.mode = 'mouse' # Enable HTML rendering\n",
        "\n",
        "# Show the plot\n",
        "show(p)"
      ],
      "metadata": {
        "id": "gZQ67l7Ro29y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new columns 'X' and 'Y' with some sample data\n",
        "df['X'] = [umap_result[x, 0] for x in range(len(df))]\n",
        "df['Y'] = [umap_result[x, 1] for x in range(len(df))]\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('spatialized actor statements.csv', index=False)"
      ],
      "metadata": {
        "id": "onHZGUU3r3L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DIY RAG (Retrieval augmented generation)\n",
        "\n",
        "Edit the cell below (query), run it and the subsequent cells, then copy the last output into an AI assistant."
      ],
      "metadata": {
        "id": "7zcA6wkhzwng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EDIT THE QUERY BELOW\n",
        "# Then execute this cell and the following ones\n",
        "\n",
        "query = \"Samsø\" # We suggest querying a question, but it could be anything\n",
        "number_of_retrieved_statements = 30"
      ],
      "metadata": {
        "id": "1iJdovmtpY6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed the query\n",
        "query_embedding = embedding_function([query])\n",
        "\n",
        "# Perform a similarity search\n",
        "results = collection.query(\n",
        "    query_embeddings=query_embedding,\n",
        "    n_results=number_of_retrieved_statements\n",
        ")\n",
        "\n",
        "# Extract the statements from results\n",
        "retrieved_txt = results['documents'][0]\n",
        "retrieved_id = results['ids'][0]\n",
        "\n",
        "# Print them\n",
        "print(\"# Extracted statements:\\n\")\n",
        "for chunk in retrieved_txt:\n",
        "  print(\"- \"+chunk)"
      ],
      "metadata": {
        "id": "FWNfmShY0j9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the plot to the notebook\n",
        "output_notebook()\n",
        "\n",
        "# Create the figure\n",
        "p = bp.figure(width=1500, height=700,\n",
        "            title=\"Actor statements\",\n",
        "            tools=\"pan,wheel_zoom,box_zoom,reset,hover\", match_aspect=True)\n",
        "\n",
        "# Add scatter plot with color mapping and hover tool\n",
        "p.scatter('x', 'y', source=source, size=10,\n",
        "        color={'field': 'attribute_to_paint', 'transform': color_mapper},\n",
        "        legend_group='attribute_to_paint')\n",
        "\n",
        "# Customize the plot (optional)\n",
        "p.legend.title = painted_attribute\n",
        "p.xaxis.axis_label = \"UMAP Dimension 1\"\n",
        "p.yaxis.axis_label = \"UMAP Dimension 2\"\n",
        "\n",
        "# Highlight retrieved data points in red\n",
        "closest_indices = [int(i) for i in retrieved_id]\n",
        "\n",
        "closest_source = ColumnDataSource(data=dict(\n",
        "    x=[umap_result[i, 0] for i in closest_indices],\n",
        "    y=[umap_result[i, 1] for i in closest_indices],\n",
        "    author=[df['Actor '][i] for i in closest_indices],\n",
        "    source=[df['Source name (e.g. LinkedIn,  Jyske Vestkysten, Folketinget, etc.)'][i] for i in closest_indices],\n",
        "    date=[df['Date of publication (today if not available)'][i] for i in closest_indices],\n",
        "    text=[df[settings['column_text']][i] for i in closest_indices]\n",
        "))\n",
        "\n",
        "p.circle('x', 'y', source=closest_source, size=25, color=\"#ee00ff\", legend_label=\"Closest statements\")\n",
        "\n",
        "\n",
        "# HTML tooltip\n",
        "hover = p.select(dict(type=HoverTool))\n",
        "hover.tooltips = \"\"\"\n",
        "    <div style=\"width: 300px; word-wrap: break-word;\">\n",
        "        <div>@text</div>\n",
        "        <div><em>&mdash;@author, @source, @date</em></div>\n",
        "        <br>\n",
        "    </div>\n",
        "\"\"\"\n",
        "hover.mode = 'mouse' # Enable HTML rendering\n",
        "\n",
        "# Show the plot\n",
        "show(p)"
      ],
      "metadata": {
        "id": "wamihGeU0vFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'''Given the context information provided, and not prior knowledge, answer the query.\n",
        "\n",
        "QUERY\n",
        "```txt\n",
        "{query}\n",
        "```\n",
        "\n",
        "CONTEXT INFORMATION\n",
        "```json\n",
        "{json.dumps(retrieved_txt)}\n",
        "```\n",
        "'''\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "KdnhPbgq176W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5vnjs_mFOFnK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}